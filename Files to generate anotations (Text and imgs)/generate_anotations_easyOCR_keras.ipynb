{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create annotations using keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: You must give at least one requirement to install (see \"pip help install\")\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alabaster==0.7.13 (from -r requirements.txt (line 2))\n",
      "  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting albumentations==1.2.1 (from -r requirements.txt (line 3))\n",
      "  Using cached albumentations-1.2.1-py3-none-any.whl (116 kB)\n",
      "Collecting altair==4.2.2 (from -r requirements.txt (line 4))\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Collecting anyio==3.6.2 (from -r requirements.txt (line 5))\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Collecting appdirs==1.4.4 (from -r requirements.txt (line 6))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting argon2-cffi==21.3.0 (from -r requirements.txt (line 7))\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from -r requirements.txt (line 8))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Collecting array-record==0.2.0 (from -r requirements.txt (line 9))\n",
      "  Using cached array_record-0.2.0-py310-none-any.whl (3.0 MB)\n",
      "Collecting arviz==0.15.1 (from -r requirements.txt (line 10))\n",
      "  Using cached arviz-0.15.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting astropy==5.2.2 (from -r requirements.txt (line 11))\n",
      "  Using cached astropy-5.2.2-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "Collecting astunparse==1.6.3 (from -r requirements.txt (line 12))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting attrs==23.1.0 (from -r requirements.txt (line 13))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting audioread==3.0.0 (from -r requirements.txt (line 14))\n",
      "  Using cached audioread-3.0.0.tar.gz (377 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting autograd==1.5 (from -r requirements.txt (line 15))\n",
      "  Using cached autograd-1.5-py3-none-any.whl (48 kB)\n",
      "Collecting Babel==2.12.1 (from -r requirements.txt (line 16))\n",
      "  Using cached Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (0.2.0)\n",
      "Collecting beautifulsoup4==4.11.2 (from -r requirements.txt (line 18))\n",
      "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "Collecting bleach==6.0.0 (from -r requirements.txt (line 19))\n",
      "  Using cached bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "Collecting blis==0.7.9 (from -r requirements.txt (line 20))\n",
      "  Using cached blis-0.7.9-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "Collecting blosc2==2.0.0 (from -r requirements.txt (line 21))\n",
      "  Using cached blosc2-2.0.0-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting bokeh==2.4.3 (from -r requirements.txt (line 22))\n",
      "  Using cached bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
      "Collecting branca==0.6.0 (from -r requirements.txt (line 23))\n",
      "  Using cached branca-0.6.0-py3-none-any.whl (24 kB)\n",
      "Collecting build==0.10.0 (from -r requirements.txt (line 24))\n",
      "  Using cached build-0.10.0-py3-none-any.whl (17 kB)\n",
      "Collecting CacheControl==0.12.11 (from -r requirements.txt (line 25))\n",
      "  Using cached CacheControl-0.12.11-py2.py3-none-any.whl (21 kB)\n",
      "Collecting cached-property==1.5.2 (from -r requirements.txt (line 26))\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting cachetools==5.3.0 (from -r requirements.txt (line 27))\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting catalogue==2.0.8 (from -r requirements.txt (line 28))\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting certifi==2022.12.7 (from -r requirements.txt (line 29))\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting cffi==1.15.1 (from -r requirements.txt (line 30))\n",
      "  Using cached cffi-1.15.1-cp310-cp310-win_amd64.whl (179 kB)\n",
      "Collecting chardet==4.0.0 (from -r requirements.txt (line 31))\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting charset-normalizer==2.0.12 (from -r requirements.txt (line 32))\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting chex==0.1.7 (from -r requirements.txt (line 33))\n",
      "  Using cached chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Collecting click==8.1.3 (from -r requirements.txt (line 34))\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting cloudpickle==2.2.1 (from -r requirements.txt (line 35))\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting cmake==3.25.2 (from -r requirements.txt (line 36))\n",
      "  Using cached cmake-3.25.2-py2.py3-none-win_amd64.whl (32.6 MB)\n",
      "Collecting cmdstanpy==1.1.0 (from -r requirements.txt (line 37))\n",
      "  Using cached cmdstanpy-1.1.0-py3-none-any.whl (83 kB)\n",
      "Collecting colorcet==3.0.1 (from -r requirements.txt (line 38))\n",
      "  Using cached colorcet-3.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting colorlover==0.3.0 (from -r requirements.txt (line 39))\n",
      "  Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Collecting community==1.0.0b1 (from -r requirements.txt (line 40))\n",
      "  Using cached community-1.0.0b1.tar.gz (2.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting confection==0.0.4 (from -r requirements.txt (line 41))\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting cons==0.4.5 (from -r requirements.txt (line 42))\n",
      "  Using cached cons-0.4.5.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting contextlib2==0.6.0.post1 (from -r requirements.txt (line 43))\n",
      "  Using cached contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting contourpy==1.0.7 (from -r requirements.txt (line 44))\n",
      "  Using cached contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
      "Collecting convertdate==2.4.0 (from -r requirements.txt (line 45))\n",
      "  Using cached convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "Collecting cryptography==40.0.2 (from -r requirements.txt (line 46))\n",
      "  Using cached cryptography-40.0.2-cp36-abi3-win_amd64.whl (2.6 MB)\n",
      "Collecting cufflinks==0.17.3 (from -r requirements.txt (line 47))\n",
      "  Using cached cufflinks-0.17.3.tar.gz (81 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting cupy-cuda11x==11.0.0 (from -r requirements.txt (line 48))\n",
      "  Using cached cupy_cuda11x-11.0.0-cp310-cp310-win_amd64.whl (62.2 MB)\n",
      "Collecting cvxopt==1.3.0 (from -r requirements.txt (line 49))\n",
      "  Using cached cvxopt-1.3.0-cp310-cp310-win_amd64.whl (12.7 MB)\n",
      "Collecting cvxpy==1.3.1 (from -r requirements.txt (line 50))\n",
      "  Using cached cvxpy-1.3.1-cp310-cp310-win_amd64.whl (889 kB)\n",
      "Collecting cycler==0.11.0 (from -r requirements.txt (line 51))\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting cymem==2.0.7 (from -r requirements.txt (line 52))\n",
      "  Using cached cymem-2.0.7-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting Cython==0.29.34 (from -r requirements.txt (line 53))\n",
      "  Using cached Cython-0.29.34-py2.py3-none-any.whl (988 kB)\n",
      "Collecting dask==2022.12.1 (from -r requirements.txt (line 54))\n",
      "  Using cached dask-2022.12.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting datascience==0.17.6 (from -r requirements.txt (line 55))\n",
      "  Using cached datascience-0.17.6-py3-none-any.whl (732 kB)\n",
      "Collecting db-dtypes==1.1.1 (from -r requirements.txt (line 56))\n",
      "  Using cached db_dtypes-1.1.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting dbus-python==1.2.16 (from -r requirements.txt (line 57))\n",
      "  Using cached dbus-python-1.2.16.tar.gz (576 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting debugpy==1.6.6 (from -r requirements.txt (line 58))\n",
      "  Using cached debugpy-1.6.6-cp310-cp310-win_amd64.whl (4.8 MB)\n",
      "Collecting decorator==4.4.2 (from -r requirements.txt (line 59))\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting defusedxml==0.7.1 (from -r requirements.txt (line 60))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting distributed==2022.12.1 (from -r requirements.txt (line 61))\n",
      "  Using cached distributed-2022.12.1-py3-none-any.whl (930 kB)\n",
      "Collecting dlib==19.24.1 (from -r requirements.txt (line 62))\n",
      "  Using cached dlib-19.24.1.tar.gz (3.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dm-tree==0.1.8 (from -r requirements.txt (line 63))\n",
      "  Using cached dm_tree-0.1.8-cp310-cp310-win_amd64.whl (101 kB)\n",
      "Collecting docutils==0.16 (from -r requirements.txt (line 64))\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Collecting dopamine-rl==4.0.6 (from -r requirements.txt (line 65))\n",
      "  Using cached dopamine_rl-4.0.6-py3-none-any.whl (179 kB)\n",
      "Collecting duckdb==0.7.1 (from -r requirements.txt (line 66))\n",
      "  Using cached duckdb-0.7.1-cp310-cp310-win_amd64.whl (9.5 MB)\n",
      "Collecting earthengine-api==0.1.350 (from -r requirements.txt (line 67))\n",
      "  Using cached earthengine-api-0.1.350.tar.gz (245 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting easydict==1.10 (from -r requirements.txt (line 68))\n",
      "  Using cached easydict-1.10.tar.gz (6.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting ecos==2.0.12 (from -r requirements.txt (line 69))\n",
      "  Using cached ecos-2.0.12-cp310-cp310-win_amd64.whl (72 kB)\n",
      "Collecting editdistance==0.6.2 (from -r requirements.txt (line 70))\n",
      "  Using cached editdistance-0.6.2-cp310-cp310-win_amd64.whl (22 kB)\n",
      "Collecting efficientnet==1.0.0 (from -r requirements.txt (line 71))\n",
      "  Using cached efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting entrypoints==0.4 (from -r requirements.txt (line 73))\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting ephem==4.1.4 (from -r requirements.txt (line 74))\n",
      "  Using cached ephem-4.1.4-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "Collecting essential-generators==1.0 (from -r requirements.txt (line 75))\n",
      "  Using cached essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting et-xmlfile==1.1.0 (from -r requirements.txt (line 76))\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting etils==1.2.0 (from -r requirements.txt (line 77))\n",
      "  Using cached etils-1.2.0-py3-none-any.whl (120 kB)\n",
      "Collecting etuples==0.3.8 (from -r requirements.txt (line 78))\n",
      "  Using cached etuples-0.3.8.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting exceptiongroup==1.1.1 (from -r requirements.txt (line 79))\n",
      "  Using cached exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting fastai==2.7.12 (from -r requirements.txt (line 80))\n",
      "  Using cached fastai-2.7.12-py3-none-any.whl (233 kB)\n",
      "Collecting fastcore==1.5.29 (from -r requirements.txt (line 81))\n",
      "  Using cached fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "Collecting fastdownload==0.0.7 (from -r requirements.txt (line 82))\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastjsonschema==2.16.3 (from -r requirements.txt (line 83))\n",
      "  Using cached fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
      "Collecting fastprogress==1.0.3 (from -r requirements.txt (line 84))\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Collecting fastrlock==0.8.1 (from -r requirements.txt (line 85))\n",
      "  Using cached fastrlock-0.8.1-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting filelock==3.12.0 (from -r requirements.txt (line 86))\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting firebase-admin==5.3.0 (from -r requirements.txt (line 87))\n",
      "  Using cached firebase_admin-5.3.0-py3-none-any.whl (117 kB)\n",
      "Collecting Flask==2.2.4 (from -r requirements.txt (line 88))\n",
      "  Using cached Flask-2.2.4-py3-none-any.whl (101 kB)\n",
      "Collecting flatbuffers==23.3.3 (from -r requirements.txt (line 89))\n",
      "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting flax==0.6.9 (from -r requirements.txt (line 90))\n",
      "  Using cached flax-0.6.9-py3-none-any.whl (226 kB)\n",
      "Collecting folium==0.14.0 (from -r requirements.txt (line 91))\n",
      "  Using cached folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
      "Collecting fonttools==4.39.3 (from -r requirements.txt (line 92))\n",
      "  Using cached fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "Collecting frozendict==2.3.7 (from -r requirements.txt (line 93))\n",
      "  Using cached frozendict-2.3.7-cp310-cp310-win_amd64.whl (34 kB)\n",
      "Collecting fsspec==2023.4.0 (from -r requirements.txt (line 94))\n",
      "  Using cached fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "Collecting future==0.18.3 (from -r requirements.txt (line 95))\n",
      "  Using cached future-0.18.3.tar.gz (840 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gast==0.4.0 (from -r requirements.txt (line 96))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting GDAL==3.3.2 (from -r requirements.txt (line 97))\n",
      "  Using cached GDAL-3.3.2.tar.gz (747 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gdown==4.6.6 (from -r requirements.txt (line 98))\n",
      "  Using cached gdown-4.6.6-py3-none-any.whl (14 kB)\n",
      "Collecting gensim==4.3.1 (from -r requirements.txt (line 99))\n",
      "  Using cached gensim-4.3.1-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "Collecting geographiclib==2.0 (from -r requirements.txt (line 100))\n",
      "  Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Collecting geopy==2.3.0 (from -r requirements.txt (line 101))\n",
      "  Using cached geopy-2.3.0-py3-none-any.whl (119 kB)\n",
      "Collecting gin-config==0.5.0 (from -r requirements.txt (line 102))\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting glob2==0.7 (from -r requirements.txt (line 103))\n",
      "  Using cached glob2-0.7.tar.gz (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting google==2.0.3 (from -r requirements.txt (line 104))\n",
      "  Using cached google-2.0.3-py2.py3-none-any.whl (45 kB)\n",
      "Collecting google-api-core==2.11.0 (from -r requirements.txt (line 105))\n",
      "  Using cached google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "Collecting google-api-python-client==2.84.0 (from -r requirements.txt (line 106))\n",
      "  Using cached google_api_python_client-2.84.0-py2.py3-none-any.whl (11.2 MB)\n",
      "Collecting google-auth==2.17.3 (from -r requirements.txt (line 107))\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-httplib2==0.1.0 (from -r requirements.txt (line 108))\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-auth-oauthlib==1.0.0 (from -r requirements.txt (line 109))\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-cloud-bigquery==3.9.0 (from -r requirements.txt (line 110))\n",
      "  Using cached google_cloud_bigquery-3.9.0-py2.py3-none-any.whl (217 kB)\n",
      "Collecting google-cloud-bigquery-storage==2.19.1 (from -r requirements.txt (line 111))\n",
      "  Using cached google_cloud_bigquery_storage-2.19.1-py2.py3-none-any.whl (190 kB)\n",
      "Collecting google-cloud-core==2.3.2 (from -r requirements.txt (line 112))\n",
      "  Using cached google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-cloud-datastore==2.15.1 (from -r requirements.txt (line 113))\n",
      "  Using cached google_cloud_datastore-2.15.1-py2.py3-none-any.whl (175 kB)\n",
      "Collecting google-cloud-firestore==2.11.0 (from -r requirements.txt (line 114))\n",
      "  Using cached google_cloud_firestore-2.11.0-py2.py3-none-any.whl (283 kB)\n",
      "Collecting google-cloud-language==2.9.1 (from -r requirements.txt (line 115))\n",
      "  Using cached google_cloud_language-2.9.1-py2.py3-none-any.whl (99 kB)\n",
      "Collecting google-cloud-storage==2.8.0 (from -r requirements.txt (line 116))\n",
      "  Using cached google_cloud_storage-2.8.0-py2.py3-none-any.whl (113 kB)\n",
      "Collecting google-cloud-translate==3.11.1 (from -r requirements.txt (line 117))\n",
      "  Using cached google_cloud_translate-3.11.1-py2.py3-none-any.whl (128 kB)\n",
      "Collecting google-crc32c==1.5.0 (from -r requirements.txt (line 118))\n",
      "  Using cached google_crc32c-1.5.0-cp310-cp310-win_amd64.whl (27 kB)\n",
      "Collecting google-pasta==0.2.0 (from -r requirements.txt (line 119))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting google-resumable-media==2.5.0 (from -r requirements.txt (line 120))\n",
      "  Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\n",
      "Collecting googleapis-common-protos==1.59.0 (from -r requirements.txt (line 121))\n",
      "  Using cached googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "Collecting googledrivedownloader==0.4 (from -r requirements.txt (line 122))\n",
      "  Using cached googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting graphviz==0.20.1 (from -r requirements.txt (line 123))\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Collecting greenlet==2.0.2 (from -r requirements.txt (line 124))\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "Collecting grpcio==1.54.0 (from -r requirements.txt (line 125))\n",
      "  Using cached grpcio-1.54.0-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "Collecting grpcio-status==1.48.2 (from -r requirements.txt (line 126))\n",
      "  Using cached grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Collecting gspread==3.4.2 (from -r requirements.txt (line 127))\n",
      "  Using cached gspread-3.4.2-py3-none-any.whl (23 kB)\n",
      "Collecting gspread-dataframe==3.0.8 (from -r requirements.txt (line 128))\n",
      "  Using cached gspread_dataframe-3.0.8-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting gym==0.25.2 (from -r requirements.txt (line 129))\n",
      "  Using cached gym-0.25.2.tar.gz (734 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gym-notices==0.0.8 (from -r requirements.txt (line 130))\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting h5netcdf==1.1.0 (from -r requirements.txt (line 131))\n",
      "  Using cached h5netcdf-1.1.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py==3.8.0 (from -r requirements.txt (line 132))\n",
      "  Using cached h5py-3.8.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting hijri-converter==2.3.1 (from -r requirements.txt (line 133))\n",
      "  Using cached hijri_converter-2.3.1-py3-none-any.whl (13 kB)\n",
      "Collecting holidays==0.23 (from -r requirements.txt (line 134))\n",
      "  Using cached holidays-0.23-py3-none-any.whl (485 kB)\n",
      "Collecting holoviews==1.15.4 (from -r requirements.txt (line 135))\n",
      "  Using cached holoviews-1.15.4-py2.py3-none-any.whl (4.3 MB)\n",
      "Collecting html5lib==1.1 (from -r requirements.txt (line 136))\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting httpimport==1.3.0 (from -r requirements.txt (line 137))\n",
      "  Using cached httpimport-1.3.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting httplib2==0.21.0 (from -r requirements.txt (line 138))\n",
      "  Using cached httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
      "Collecting humanize==4.6.0 (from -r requirements.txt (line 139))\n",
      "  Using cached humanize-4.6.0-py3-none-any.whl (109 kB)\n",
      "Collecting hyperopt==0.2.7 (from -r requirements.txt (line 140))\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting idna==3.4 (from -r requirements.txt (line 141))\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting imageio==2.25.1 (from -r requirements.txt (line 142))\n",
      "  Using cached imageio-2.25.1-py3-none-any.whl (3.4 MB)\n",
      "Collecting imageio-ffmpeg==0.4.8 (from -r requirements.txt (line 143))\n",
      "  Using cached imageio_ffmpeg-0.4.8-py3-none-win_amd64.whl (22.6 MB)\n",
      "Collecting imagesize==1.4.1 (from -r requirements.txt (line 144))\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting imbalanced-learn==0.10.1 (from -r requirements.txt (line 145))\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Collecting imgaug==0.4.0 (from -r requirements.txt (line 146))\n",
      "  Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Collecting importlib-resources==5.12.0 (from -r requirements.txt (line 147))\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting imutils==0.5.4 (from -r requirements.txt (line 148))\n",
      "  Using cached imutils-0.5.4.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting inflect==6.0.4 (from -r requirements.txt (line 149))\n",
      "  Using cached inflect-6.0.4-py3-none-any.whl (34 kB)\n",
      "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 150))\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting intel-openmp==2023.1.0 (from -r requirements.txt (line 151))\n",
      "  Using cached intel_openmp-2023.1.0-py2.py3-none-win_amd64.whl (4.2 MB)\n",
      "Collecting ipykernel==5.5.6 (from -r requirements.txt (line 152))\n",
      "  Using cached ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
      "Collecting ipython==7.34.0 (from -r requirements.txt (line 153))\n",
      "  Using cached ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "Collecting ipython-genutils==0.2.0 (from -r requirements.txt (line 154))\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ipython-sql==0.4.1 (from -r requirements.txt (line 155))\n",
      "  Using cached ipython_sql-0.4.1-py3-none-any.whl (21 kB)\n",
      "Collecting ipywidgets==7.7.1 (from -r requirements.txt (line 156))\n",
      "  Using cached ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "Collecting itsdangerous==2.1.2 (from -r requirements.txt (line 157))\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting jax==0.4.8 (from -r requirements.txt (line 158))\n",
      "  Using cached jax-0.4.8.tar.gz (1.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting jieba==0.42.1 (from -r requirements.txt (line 160))\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting Jinja2==3.1.2 (from -r requirements.txt (line 161))\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting joblib==1.2.0 (from -r requirements.txt (line 162))\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting jsonpickle==3.0.1 (from -r requirements.txt (line 163))\n",
      "  Using cached jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
      "Collecting jsonschema==4.3.3 (from -r requirements.txt (line 164))\n",
      "  Using cached jsonschema-4.3.3-py3-none-any.whl (71 kB)\n",
      "Collecting jupyter-client==6.1.12 (from -r requirements.txt (line 165))\n",
      "  Using cached jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
      "Collecting jupyter-console==6.1.0 (from -r requirements.txt (line 166))\n",
      "  Using cached jupyter_console-6.1.0-py2.py3-none-any.whl (21 kB)\n",
      "Collecting jupyter-server==1.24.0 (from -r requirements.txt (line 167))\n",
      "  Using cached jupyter_server-1.24.0-py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: jupyter_core==5.3.0 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 168)) (5.3.0)\n",
      "Collecting jupyterlab-pygments==0.2.2 (from -r requirements.txt (line 169))\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting jupyterlab-widgets==3.0.7 (from -r requirements.txt (line 170))\n",
      "  Using cached jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "Collecting kaggle==1.5.13 (from -r requirements.txt (line 171))\n",
      "  Using cached kaggle-1.5.13.tar.gz (63 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting keras==2.12.0 (from -r requirements.txt (line 172))\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting Keras-Applications==1.0.8 (from -r requirements.txt (line 173))\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting keras-ocr==0.8.9 (from -r requirements.txt (line 174))\n",
      "  Using cached keras_ocr-0.8.9-py3-none-any.whl (41 kB)\n",
      "Collecting kiwisolver==1.4.4 (from -r requirements.txt (line 175))\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting korean-lunar-calendar==0.3.1 (from -r requirements.txt (line 176))\n",
      "  Using cached korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Collecting langcodes==3.3.0 (from -r requirements.txt (line 177))\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting lazy_loader==0.2 (from -r requirements.txt (line 178))\n",
      "  Using cached lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting libclang==16.0.0 (from -r requirements.txt (line 179))\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting librosa==0.10.0.post2 (from -r requirements.txt (line 180))\n",
      "  Using cached librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "Collecting lightgbm==3.3.5 (from -r requirements.txt (line 181))\n",
      "  Using cached lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting lit==16.0.5 (from -r requirements.txt (line 182))\n",
      "  Using cached lit-16.0.5.tar.gz (138 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting llvmlite==0.39.1 (from -r requirements.txt (line 183))\n",
      "  Using cached llvmlite-0.39.1-cp310-cp310-win_amd64.whl (23.2 MB)\n",
      "Collecting locket==1.0.0 (from -r requirements.txt (line 184))\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting logical-unification==0.4.5 (from -r requirements.txt (line 185))\n",
      "  Using cached logical-unification-0.4.5.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting LunarCalendar==0.0.9 (from -r requirements.txt (line 186))\n",
      "  Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl (18 kB)\n",
      "Collecting lxml==4.9.2 (from -r requirements.txt (line 187))\n",
      "  Using cached lxml-4.9.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "Collecting Markdown==3.4.3 (from -r requirements.txt (line 188))\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting markdown-it-py==2.2.0 (from -r requirements.txt (line 189))\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting MarkupSafe==2.1.2 (from -r requirements.txt (line 190))\n",
      "  Using cached MarkupSafe-2.1.2-cp310-cp310-win_amd64.whl (16 kB)\n",
      "Collecting matplotlib==3.7.1 (from -r requirements.txt (line 191))\n",
      "  Using cached matplotlib-3.7.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 192)) (0.1.6)\n",
      "Collecting matplotlib-venn==0.11.9 (from -r requirements.txt (line 193))\n",
      "  Using cached matplotlib-venn-0.11.9.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 194))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting miniKanren==1.0.3 (from -r requirements.txt (line 195))\n",
      "  Using cached miniKanren-1.0.3.tar.gz (41 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting missingno==0.5.2 (from -r requirements.txt (line 196))\n",
      "  Using cached missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Collecting mistune==0.8.4 (from -r requirements.txt (line 197))\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting mizani==0.8.1 (from -r requirements.txt (line 198))\n",
      "  Using cached mizani-0.8.1-py3-none-any.whl (64 kB)\n",
      "Collecting mkl==2019.0 (from -r requirements.txt (line 199))\n",
      "  Using cached mkl-2019.0-py2.py3-none-win_amd64.whl (224.1 MB)\n",
      "Collecting ml-dtypes==0.1.0 (from -r requirements.txt (line 200))\n",
      "  Using cached ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "Collecting mlxtend==0.14.0 (from -r requirements.txt (line 201))\n",
      "  Using cached mlxtend-0.14.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting more-itertools==9.1.0 (from -r requirements.txt (line 202))\n",
      "  Using cached more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting moviepy==1.0.3 (from -r requirements.txt (line 203))\n",
      "  Using cached moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 204))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting msgpack==1.0.5 (from -r requirements.txt (line 205))\n",
      "  Using cached msgpack-1.0.5-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting multipledispatch==0.6.0 (from -r requirements.txt (line 206))\n",
      "  Using cached multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting multitasking==0.0.11 (from -r requirements.txt (line 207))\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting murmurhash==1.0.9 (from -r requirements.txt (line 208))\n",
      "  Using cached murmurhash-1.0.9-cp310-cp310-win_amd64.whl (18 kB)\n",
      "Collecting music21==8.1.0 (from -r requirements.txt (line 209))\n",
      "  Using cached music21-8.1.0-py3-none-any.whl (22.8 MB)\n",
      "Collecting natsort==8.3.1 (from -r requirements.txt (line 210))\n",
      "  Using cached natsort-8.3.1-py3-none-any.whl (38 kB)\n",
      "Collecting nbclient==0.7.4 (from -r requirements.txt (line 211))\n",
      "  Using cached nbclient-0.7.4-py3-none-any.whl (73 kB)\n",
      "Collecting nbconvert==6.5.4 (from -r requirements.txt (line 212))\n",
      "  Using cached nbconvert-6.5.4-py3-none-any.whl (563 kB)\n",
      "Collecting nbformat==5.8.0 (from -r requirements.txt (line 213))\n",
      "  Using cached nbformat-5.8.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 214)) (1.5.6)\n",
      "Collecting networkx==3.1 (from -r requirements.txt (line 215))\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting nibabel==3.0.2 (from -r requirements.txt (line 216))\n",
      "  Using cached nibabel-3.0.2-py3-none-any.whl (3.3 MB)\n",
      "Collecting nltk==3.8.1 (from -r requirements.txt (line 217))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting notebook==6.4.8 (from -r requirements.txt (line 218))\n",
      "  Using cached notebook-6.4.8-py3-none-any.whl (9.9 MB)\n",
      "Collecting numba==0.56.4 (from -r requirements.txt (line 219))\n",
      "  Using cached numba-0.56.4-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Collecting numexpr==2.8.4 (from -r requirements.txt (line 220))\n",
      "  Using cached numexpr-2.8.4-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Collecting numpy==1.22.4 (from -r requirements.txt (line 221))\n",
      "  Using cached numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "Collecting oauth2client==4.1.3 (from -r requirements.txt (line 222))\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting oauthlib==3.2.2 (from -r requirements.txt (line 223))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting opencv-contrib-python==4.7.0.72 (from -r requirements.txt (line 224))\n",
      "  Using cached opencv_contrib_python-4.7.0.72-cp37-abi3-win_amd64.whl (44.9 MB)\n",
      "Collecting opencv-python==4.7.0.72 (from -r requirements.txt (line 225))\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Collecting opencv-python-headless==4.7.0.72 (from -r requirements.txt (line 226))\n",
      "  Using cached opencv_python_headless-4.7.0.72-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Collecting openpyxl==3.0.10 (from -r requirements.txt (line 227))\n",
      "  Using cached openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
      "Collecting opt-einsum==3.3.0 (from -r requirements.txt (line 228))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting optax==0.1.5 (from -r requirements.txt (line 229))\n",
      "  Using cached optax-0.1.5-py3-none-any.whl (164 kB)\n",
      "Collecting orbax-checkpoint==0.2.1 (from -r requirements.txt (line 230))\n",
      "  Using cached orbax_checkpoint-0.2.1-py3-none-any.whl (78 kB)\n",
      "Collecting osqp==0.6.2.post8 (from -r requirements.txt (line 231))\n",
      "  Using cached osqp-0.6.2.post8-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Requirement already satisfied: packaging==23.1 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 232)) (23.1)\n",
      "Collecting palettable==3.3.3 (from -r requirements.txt (line 233))\n",
      "  Using cached palettable-3.3.3-py2.py3-none-any.whl (332 kB)\n",
      "Collecting pandas==1.5.3 (from -r requirements.txt (line 234))\n",
      "  Using cached pandas-1.5.3-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "Collecting pandas-datareader==0.10.0 (from -r requirements.txt (line 235))\n",
      "  Using cached pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Collecting pandas-gbq==0.17.9 (from -r requirements.txt (line 236))\n",
      "  Using cached pandas_gbq-0.17.9-py2.py3-none-any.whl (25 kB)\n",
      "Collecting pandocfilters==1.5.0 (from -r requirements.txt (line 237))\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting panel==0.14.4 (from -r requirements.txt (line 238))\n",
      "  Using cached panel-0.14.4-py2.py3-none-any.whl (20.8 MB)\n",
      "Collecting param==1.13.0 (from -r requirements.txt (line 239))\n",
      "  Using cached param-1.13.0-py2.py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 240)) (0.8.3)\n",
      "Collecting partd==1.4.0 (from -r requirements.txt (line 241))\n",
      "  Using cached partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting pathlib==1.0.1 (from -r requirements.txt (line 242))\n",
      "  Using cached pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Collecting pathy==0.10.1 (from -r requirements.txt (line 243))\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting patsy==0.5.3 (from -r requirements.txt (line 244))\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting pexpect==4.8.0 (from -r requirements.txt (line 245))\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 246)) (0.7.5)\n",
      "Collecting Pillow==8.4.0 (from -r requirements.txt (line 247))\n",
      "  Using cached Pillow-8.4.0-cp310-cp310-win_amd64.whl (3.2 MB)\n",
      "Collecting pip-tools==6.13.0 (from -r requirements.txt (line 248))\n",
      "  Using cached pip_tools-6.13.0-py3-none-any.whl (53 kB)\n",
      "Collecting platformdirs==3.3.0 (from -r requirements.txt (line 249))\n",
      "  Using cached platformdirs-3.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting plotly==5.13.1 (from -r requirements.txt (line 250))\n",
      "  Using cached plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
      "Collecting plotnine==0.10.1 (from -r requirements.txt (line 251))\n",
      "  Using cached plotnine-0.10.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting pluggy==1.0.0 (from -r requirements.txt (line 252))\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting polars==0.17.3 (from -r requirements.txt (line 253))\n",
      "  Using cached polars-0.17.3-cp37-abi3-win_amd64.whl (18.0 MB)\n",
      "Collecting pooch==1.6.0 (from -r requirements.txt (line 254))\n",
      "  Using cached pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "Collecting portpicker==1.3.9 (from -r requirements.txt (line 255))\n",
      "  Using cached portpicker-1.3.9-py3-none-any.whl (13 kB)\n",
      "Collecting prefetch-generator==1.0.3 (from -r requirements.txt (line 256))\n",
      "  Using cached prefetch_generator-1.0.3.tar.gz (4.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting preshed==3.0.8 (from -r requirements.txt (line 257))\n",
      "  Using cached preshed-3.0.8-cp310-cp310-win_amd64.whl (94 kB)\n",
      "Collecting prettytable==0.7.2 (from -r requirements.txt (line 258))\n",
      "  Using cached prettytable-0.7.2.zip (28 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting proglog==0.1.10 (from -r requirements.txt (line 259))\n",
      "  Using cached proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Collecting progressbar2==4.2.0 (from -r requirements.txt (line 260))\n",
      "  Using cached progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting prometheus-client==0.16.0 (from -r requirements.txt (line 261))\n",
      "  Using cached prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
      "Collecting promise==2.3 (from -r requirements.txt (line 262))\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: prompt-toolkit==3.0.38 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 263)) (3.0.38)\n",
      "Collecting prophet==1.1.2 (from -r requirements.txt (line 264))\n",
      "  Using cached prophet-1.1.2-py3-none-win_amd64.whl (12.1 MB)\n",
      "Collecting proto-plus==1.22.2 (from -r requirements.txt (line 265))\n",
      "  Using cached proto_plus-1.22.2-py3-none-any.whl (47 kB)\n",
      "Collecting protobuf==3.20.3 (from -r requirements.txt (line 266))\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: psutil==5.9.5 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 267)) (5.9.5)\n",
      "Collecting psycopg2==2.9.6 (from -r requirements.txt (line 268))\n",
      "  Using cached psycopg2-2.9.6-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Collecting ptyprocess==0.7.0 (from -r requirements.txt (line 269))\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting py-cpuinfo==9.0.0 (from -r requirements.txt (line 270))\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting py4j==0.10.9.7 (from -r requirements.txt (line 271))\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Collecting pyarrow==9.0.0 (from -r requirements.txt (line 272))\n",
      "  Using cached pyarrow-9.0.0-cp310-cp310-win_amd64.whl (19.5 MB)\n",
      "Collecting pyasn1==0.5.0 (from -r requirements.txt (line 273))\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting pyasn1-modules==0.3.0 (from -r requirements.txt (line 274))\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting pyclipper==1.3.0.post4 (from -r requirements.txt (line 275))\n",
      "  Using cached pyclipper-1.3.0.post4-cp310-cp310-win_amd64.whl (94 kB)\n",
      "Collecting pycocotools==2.0.6 (from -r requirements.txt (line 276))\n",
      "  Using cached pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pycparser==2.21 (from -r requirements.txt (line 277))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting pyct==0.5.0 (from -r requirements.txt (line 278))\n",
      "  Using cached pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting pydantic==1.10.7 (from -r requirements.txt (line 279))\n",
      "  Using cached pydantic-1.10.7-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting pydata-google-auth==1.7.0 (from -r requirements.txt (line 280))\n",
      "  Using cached pydata_google_auth-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting pydot==1.4.2 (from -r requirements.txt (line 281))\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pydot-ng==2.0.0 (from -r requirements.txt (line 282))\n",
      "  Using cached pydot_ng-2.0.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting pydotplus==2.0.2 (from -r requirements.txt (line 283))\n",
      "  Using cached pydotplus-2.0.2.tar.gz (278 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting PyDrive==1.3.1 (from -r requirements.txt (line 284))\n",
      "  Using cached PyDrive-1.3.1.tar.gz (987 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyerfa==2.0.0.3 (from -r requirements.txt (line 285))\n",
      "  Using cached pyerfa-2.0.0.3-cp310-cp310-win_amd64.whl (347 kB)\n",
      "Collecting pygame==2.3.0 (from -r requirements.txt (line 286))\n",
      "  Using cached pygame-2.3.0-cp310-cp310-win_amd64.whl (10.5 MB)\n",
      "Collecting Pygments==2.14.0 (from -r requirements.txt (line 287))\n",
      "  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting PyGObject==3.36.0 (from -r requirements.txt (line 288))\n",
      "  Using cached PyGObject-3.36.0.tar.gz (714 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pymc==5.1.2 (from -r requirements.txt (line 289))\n",
      "  Using cached pymc-5.1.2-py3-none-any.whl (433 kB)\n",
      "Collecting PyMeeus==0.5.12 (from -r requirements.txt (line 290))\n",
      "  Using cached PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pymystem3==0.2.0 (from -r requirements.txt (line 291))\n",
      "  Using cached pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting PyOpenGL==3.1.6 (from -r requirements.txt (line 292))\n",
      "  Using cached PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\n",
      "Collecting pyparsing==3.0.9 (from -r requirements.txt (line 293))\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting pyproject_hooks==1.0.0 (from -r requirements.txt (line 294))\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyrsistent==0.19.3 (from -r requirements.txt (line 295))\n",
      "  Using cached pyrsistent-0.19.3-cp310-cp310-win_amd64.whl (62 kB)\n",
      "Collecting PySocks==1.7.1 (from -r requirements.txt (line 296))\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting pytensor==2.10.1 (from -r requirements.txt (line 297))\n",
      "  Using cached pytensor-2.10.1-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "Collecting pytest==7.2.2 (from -r requirements.txt (line 298))\n",
      "  Using cached pytest-7.2.2-py3-none-any.whl (317 kB)\n",
      "Collecting python-apt==0.0.0 (from -r requirements.txt (line 299))\n",
      "  Using cached python-apt-0.0.0.tar.bz2 (105 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 300)) (2.8.2)\n",
      "Collecting python-louvain==0.16 (from -r requirements.txt (line 301))\n",
      "  Using cached python-louvain-0.16.tar.gz (204 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting python-slugify==8.0.1 (from -r requirements.txt (line 302))\n",
      "  Using cached python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting python-utils==3.5.2 (from -r requirements.txt (line 303))\n",
      "  Using cached python_utils-3.5.2-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pytz==2022.7.1 (from -r requirements.txt (line 304))\n",
      "  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "Collecting pytz-deprecation-shim==0.1.0.post0 (from -r requirements.txt (line 305))\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting pyviz-comms==2.2.1 (from -r requirements.txt (line 306))\n",
      "  Using cached pyviz_comms-2.2.1-py2.py3-none-any.whl (42 kB)\n",
      "Collecting PyWavelets==1.4.1 (from -r requirements.txt (line 307))\n",
      "  Using cached PyWavelets-1.4.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "Collecting PyYAML==6.0 (from -r requirements.txt (line 308))\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting pyzmq==23.2.1 (from -r requirements.txt (line 309))\n",
      "  Using cached pyzmq-23.2.1-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Collecting qdldl==0.1.7 (from -r requirements.txt (line 310))\n",
      "  Using cached qdldl-0.1.7-cp310-cp310-win_amd64.whl (83 kB)\n",
      "Collecting qudida==0.0.4 (from -r requirements.txt (line 311))\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting regex==2022.10.31 (from -r requirements.txt (line 312))\n",
      "  Using cached regex-2022.10.31-cp310-cp310-win_amd64.whl (267 kB)\n",
      "Collecting requests==2.27.1 (from -r requirements.txt (line 313))\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting requests-oauthlib==1.3.1 (from -r requirements.txt (line 314))\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting requests-unixsocket==0.2.0 (from -r requirements.txt (line 315))\n",
      "  Using cached requests_unixsocket-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting requirements-parser==0.5.0 (from -r requirements.txt (line 316))\n",
      "  Using cached requirements_parser-0.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting rich==13.3.4 (from -r requirements.txt (line 317))\n",
      "  Using cached rich-13.3.4-py3-none-any.whl (238 kB)\n",
      "Collecting rsa==4.9 (from -r requirements.txt (line 319))\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting scikit-image==0.19.3 (from -r requirements.txt (line 320))\n",
      "  Using cached scikit_image-0.19.3-cp310-cp310-win_amd64.whl (12.0 MB)\n",
      "Collecting scikit-learn==1.2.2 (from -r requirements.txt (line 321))\n",
      "  Using cached scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "Collecting scipy==1.10.1 (from -r requirements.txt (line 322))\n",
      "  Using cached scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Collecting scs==3.2.3 (from -r requirements.txt (line 323))\n",
      "  Using cached scs-3.2.3-cp310-cp310-win_amd64.whl (8.2 MB)\n",
      "Collecting seaborn==0.12.2 (from -r requirements.txt (line 324))\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting Send2Trash==1.8.0 (from -r requirements.txt (line 325))\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting shapely==2.0.1 (from -r requirements.txt (line 326))\n",
      "  Using cached shapely-2.0.1-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\maria\\github-classroom\\dcc-uab\\dlnn-project_ia-group_15\\.venv\\lib\\site-packages (from -r requirements.txt (line 327)) (1.16.0)\n",
      "Collecting sklearn-pandas==2.2.0 (from -r requirements.txt (line 328))\n",
      "  Using cached sklearn_pandas-2.2.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting smart-open==6.3.0 (from -r requirements.txt (line 329))\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting sniffio==1.3.0 (from -r requirements.txt (line 330))\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting snowballstemmer==2.2.0 (from -r requirements.txt (line 331))\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting sortedcontainers==2.4.0 (from -r requirements.txt (line 332))\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting soundfile==0.12.1 (from -r requirements.txt (line 333))\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting soupsieve==2.4.1 (from -r requirements.txt (line 334))\n",
      "  Using cached soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Collecting soxr==0.3.5 (from -r requirements.txt (line 335))\n",
      "  Using cached soxr-0.3.5-cp310-cp310-win_amd64.whl (184 kB)\n",
      "Collecting spacy==3.5.2 (from -r requirements.txt (line 336))\n",
      "  Using cached spacy-3.5.2-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "Collecting spacy-legacy==3.0.12 (from -r requirements.txt (line 337))\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers==1.0.4 (from -r requirements.txt (line 338))\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting Sphinx==3.5.4 (from -r requirements.txt (line 339))\n",
      "  Using cached Sphinx-3.5.4-py3-none-any.whl (2.8 MB)\n",
      "Collecting sphinxcontrib-applehelp==1.0.4 (from -r requirements.txt (line 340))\n",
      "  Using cached sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
      "Collecting sphinxcontrib-devhelp==1.0.2 (from -r requirements.txt (line 341))\n",
      "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting sphinxcontrib-htmlhelp==2.0.1 (from -r requirements.txt (line 342))\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
      "Collecting sphinxcontrib-jsmath==1.0.1 (from -r requirements.txt (line 343))\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-qthelp==1.0.3 (from -r requirements.txt (line 344))\n",
      "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Collecting sphinxcontrib-serializinghtml==1.1.5 (from -r requirements.txt (line 345))\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Collecting SQLAlchemy==2.0.10 (from -r requirements.txt (line 346))\n",
      "  Using cached SQLAlchemy-2.0.10-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting sqlparse==0.4.4 (from -r requirements.txt (line 347))\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting srsly==2.4.6 (from -r requirements.txt (line 348))\n",
      "  Using cached srsly-2.4.6-cp310-cp310-win_amd64.whl (480 kB)\n",
      "Collecting statsmodels==0.13.5 (from -r requirements.txt (line 349))\n",
      "  Using cached statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "Collecting sympy==1.11.1 (from -r requirements.txt (line 350))\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting tables==3.8.0 (from -r requirements.txt (line 351))\n",
      "  Using cached tables-3.8.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting tabulate==0.8.10 (from -r requirements.txt (line 352))\n",
      "  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting tblib==1.7.0 (from -r requirements.txt (line 353))\n",
      "  Using cached tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tenacity==8.2.2 (from -r requirements.txt (line 354))\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting tensorboard==2.12.2 (from -r requirements.txt (line 355))\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorboard-data-server==0.7.0 (from -r requirements.txt (line 356))\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit==1.8.1 (from -r requirements.txt (line 357))\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorflow==2.12.0 (from -r requirements.txt (line 358))\n",
      "  Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-datasets==4.9.2 (from -r requirements.txt (line 359))\n",
      "  Using cached tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "Collecting tensorflow-estimator==2.12.0 (from -r requirements.txt (line 360))\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting tensorflow-gcs-config==2.12.0 (from -r requirements.txt (line 361))\n",
      "  Using cached tensorflow_gcs_config-2.12.0-py3-none-any.whl (316 kB)\n",
      "Collecting tensorflow-hub==0.13.0 (from -r requirements.txt (line 362))\n",
      "  Using cached tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.31.0 (from -r requirements.txt (line 363))\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     ------                                   0.2/1.5 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------                                0.4/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "     ----------------                         0.6/1.5 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------                    0.8/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------           1.1/1.5 MB 4.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       1.3/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-metadata==1.13.1 (from -r requirements.txt (line 364))\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Collecting tensorflow-probability==0.20.1 (from -r requirements.txt (line 365))\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "                                              0.0/6.9 MB ? eta -:--:--\n",
      "     -                                        0.2/6.9 MB 10.2 MB/s eta 0:00:01\n",
      "     --                                       0.5/6.9 MB 5.3 MB/s eta 0:00:02\n",
      "     -----                                    1.0/6.9 MB 6.9 MB/s eta 0:00:01\n",
      "     --------                                 1.4/6.9 MB 7.4 MB/s eta 0:00:01\n",
      "     ----------                               1.8/6.9 MB 7.6 MB/s eta 0:00:01\n",
      "     ------------                             2.1/6.9 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------                            2.4/6.9 MB 7.2 MB/s eta 0:00:01\n",
      "     ----------------                         2.8/6.9 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------                       3.2/6.9 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------                    3.7/6.9 MB 7.5 MB/s eta 0:00:01\n",
      "     -----------------------                  4.1/6.9 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------                4.5/6.9 MB 7.5 MB/s eta 0:00:01\n",
      "     --------------------------               4.6/6.9 MB 7.2 MB/s eta 0:00:01\n",
      "     --------------------------               4.6/6.9 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------               4.6/6.9 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------              4.8/6.9 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------           5.2/6.9 MB 6.3 MB/s eta 0:00:01\n",
      "     -------------------------------          5.5/6.9 MB 6.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.0/6.9 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.2/6.9 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.8/6.9 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.9/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.9/6.9 MB 6.2 MB/s eta 0:00:00\n",
      "Collecting tensorstore==0.1.36 (from -r requirements.txt (line 366))\n",
      "  Downloading tensorstore-0.1.36-cp310-cp310-win_amd64.whl (8.4 MB)\n",
      "                                              0.0/8.4 MB ? eta -:--:--\n",
      "     ---                                      0.7/8.4 MB 13.9 MB/s eta 0:00:01\n",
      "     -----                                    1.2/8.4 MB 13.0 MB/s eta 0:00:01\n",
      "     ---------                                2.0/8.4 MB 13.9 MB/s eta 0:00:01\n",
      "     ------------                             2.5/8.4 MB 13.5 MB/s eta 0:00:01\n",
      "     --------------                           3.1/8.4 MB 13.1 MB/s eta 0:00:01\n",
      "     -----------------                        3.7/8.4 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------                     4.4/8.4 MB 13.2 MB/s eta 0:00:01\n",
      "     -----------------------                  5.0/8.4 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------------               5.7/8.4 MB 13.4 MB/s eta 0:00:01\n",
      "     -----------------------------            6.2/8.4 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------------------         6.9/8.4 MB 13.3 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.5/8.4 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   8.1/8.4 MB 13.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.4/8.4 MB 13.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.4/8.4 MB 12.0 MB/s eta 0:00:00\n",
      "Collecting termcolor==2.3.0 (from -r requirements.txt (line 367))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting terminado==0.17.1 (from -r requirements.txt (line 368))\n",
      "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
      "Collecting text-unidecode==1.3 (from -r requirements.txt (line 369))\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.2/78.2 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting textblob==0.17.1 (from -r requirements.txt (line 370))\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "                                              0.0/636.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 636.8/636.8 kB 13.3 MB/s eta 0:00:00\n",
      "Collecting tf-slim==1.1.0 (from -r requirements.txt (line 371))\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "                                              0.0/352.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 352.1/352.1 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting thinc==8.1.9 (from -r requirements.txt (line 372))\n",
      "  Downloading thinc-8.1.9-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     --------------------                     0.8/1.5 MB 15.9 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.4/1.5 MB 14.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl==3.1.0 (from -r requirements.txt (line 373))\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting tifffile==2023.4.12 (from -r requirements.txt (line 374))\n",
      "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
      "                                              0.0/219.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 219.4/219.4 kB ? eta 0:00:00\n",
      "Collecting tinycss2==1.2.1 (from -r requirements.txt (line 375))\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting toml==0.10.2 (from -r requirements.txt (line 376))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tomli==2.0.1 (from -r requirements.txt (line 377))\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting toolz==0.12.0 (from -r requirements.txt (line 378))\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "                                              0.0/55.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting tornado==6.3.1 (from -r requirements.txt (line 385))\n",
      "  Downloading tornado-6.3.1-cp38-abi3-win_amd64.whl (428 kB)\n",
      "                                              0.0/428.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 428.2/428.2 kB 13.1 MB/s eta 0:00:00\n",
      "Collecting tqdm==4.65.0 (from -r requirements.txt (line 386))\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting traitlets==5.7.1 (from -r requirements.txt (line 387))\n",
      "  Downloading traitlets-5.7.1-py3-none-any.whl (109 kB)\n",
      "                                              0.0/109.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 109.9/109.9 kB ? eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.0.1a1 Requires-Python >=3.6, <3.10; 0.0.1a2 Requires-Python >=3.6, <3.10; 0.1.0 Requires-Python >=3.6, <3.10; 0.1.1 Requires-Python >=3.6, <3.10; 0.2.0 Requires-Python >=3.6, <3.10; 0.23.0 Requires-Python >=3.6, <3.10; 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.5.0 Requires-Python >=2.7,<3; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 0.6.0 Requires-Python >=2.7,<=3.7; 0.9.0 Requires-Python >=2.7,<=3.7; 0.9.0 Requires-Python >=3.7.5,<3.10; 0.9.1 Requires-Python >=3.7.5,<3.10; 0.9.2 Requires-Python >=3.7.5,<3.10; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.0rc1 Requires-Python >=3.7,<3.10; 1.7.0rc2 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 2.10.0 Requires-Python >=3.6, <3.10; 2.11.0 Requires-Python >=3.6, <3.10; 2.12.0 Requires-Python >=3.6, <3.10; 2.13.0 Requires-Python >=3.6, <3.10; 2.13.1 Requires-Python >=3.6, <3.10; 2.14.0 Requires-Python >=3.6, <3.10; 2.15.0 Requires-Python >=3.6, <3.10; 2.16.0 Requires-Python >=3.6, <3.10; 2.16.1 Requires-Python >=3.6, <3.10; 2.17.0 Requires-Python >=3.6, <3.10; 2.18.0 Requires-Python >=3.6, <3.10; 2.19.0 Requires-Python >=3.6, <3.10; 2.20.0 Requires-Python >=3.6, <3.10; 2.21.0 Requires-Python >=3.6, <3.10; 2.22.0 Requires-Python >=3.6, <3.10; 2.22.1 Requires-Python >=3.6, <3.10; 2.23.0 Requires-Python >=3.6, <3.10; 2.23.1 Requires-Python >=3.6, <3.10; 2.23.2 Requires-Python >=3.6, <3.10; 2.23.3 Requires-Python >=3.6, <3.10; 2.24.0 Requires-Python >=3.6, <3.10; 2.24.1 Requires-Python >=3.6, <3.10; 2.25.0 Requires-Python >=3.6, <3.10; 2.25.1 Requires-Python >=3.6, <3.10; 2.25.2 Requires-Python >=3.6, <3.10; 2.26.0 Requires-Python >=3.6, <3.10; 2.27.0 Requires-Python >=3.6, <3.10; 2.27.1 Requires-Python >=3.6, <3.10; 2.28.0 Requires-Python >=3.6, <3.10; 2.28.1 Requires-Python >=3.6, <3.10; 2.29.0 Requires-Python >=3.6, <3.10; 2.5.2 Requires-Python !=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,<3.9dev,>=2.7; 2.6.2 Requires-Python >=3.6, <3.9; 2.7.0 Requires-Python >=3.6, <3.10; 2.8.0 Requires-Python >=3.6, <3.10; 2.9.0 Requires-Python >=3.6, <3.10\n",
      "ERROR: Could not find a version that satisfies the requirement triton==2.0.0 (from versions: none)\n",
      "ERROR: No matching distribution found for triton==2.0.0\n"
     ]
    }
   ],
   "source": [
    "#install the libraries from requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_ocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17948\\3824730208.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_ocr'"
     ]
    }
   ],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = r\"C:\\Users\\Maria\\OneDrive - UAB\\Documentos\\2 de IA\\NN and Deep Learning\\Project\\data\\JPEGImages\"\n",
    "name_imgs = os.listdir(path_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (989326716.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [18]\u001b[1;36m\u001b[0m\n\u001b[1;33m    tokens_imgs[]\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#from each group keep the word\n",
    "images = [keras_ocr.tools.read(path_folder + \"/\" + img) for img in name_imgs]\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "tokens_imgs = {}\n",
    "for image, predictions in zip(images, prediction_groups):\n",
    "    tokens_imgs[image] = [[token[0] for token in predictions]]\n",
    "\n",
    "#resize the imges and save them in rgb format\n",
    "for image in images:\n",
    "    image = keras_ocr.tools.resize_image(image, max_scale=2, max_size = 2048)\n",
    "    # print the shape of the image\n",
    "    \n",
    "\n",
    "\n",
    "df_anotations = pd.DataFrame.from_dict(tokens_imgs, orient='index', columns=['text_detected'])\n",
    "df_anotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anotations.to_pickle(\"anotations_keras.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the anotations extracted in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n04075916_5300.jpg</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02791270_185.jpg</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n02776631_12628.jpg</th>\n",
       "      <td>[at, hakone, baker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n03032252_37714.jpg</th>\n",
       "      <td>[dregal, cnlema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n03952576_12482.jpg</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text_detected\n",
       "n04075916_5300.jpg                    []\n",
       "n02791270_185.jpg                     []\n",
       "n02776631_12628.jpg  [at, hakone, baker]\n",
       "n03032252_37714.jpg     [dregal, cnlema]\n",
       "n03952576_12482.jpg                   []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#open all the files from C:\\Users\\Maria\\OneDrive - UAB\\Documentos\\2 de IA\\NN and Deep Learning\\Project\\Anotations and create a dictionary containing all the dictionaries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_folder = r\"C:\\Users\\Maria\\OneDrive - UAB\\Documentos\\2 de IA\\NN and Deep Learning\\Project\\Anotations\"\n",
    "files = os.listdir(path_folder)\n",
    "dict_anotations = {}\n",
    "for file in files:\n",
    "    temp_anotations = pd.read_pickle(path_folder + \"/\" + file)\n",
    "    dict_anotations.update(temp_anotations)\n",
    "\n",
    "print(len(dict_anotations))\n",
    "\n",
    "df_anotations = pd.DataFrame.from_dict(dict_anotations, orient='index', columns=['text_detected'])\n",
    "display(df_anotations.head())\n",
    "\n",
    "#save in a pickle file called anotations_keras.pkl\n",
    "import pickle\n",
    "\n",
    "with open('anotations_keras.pkl', 'wb') as f:\n",
    "    pickle.dump(df_anotations, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
